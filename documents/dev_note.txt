Combining
It is not necessary to have a local combiner for "each mapper", but it is necessary to combine (key, val) pair into
(key, valS) pair.

Make sure to understand shuffle and combine difference.

Shuffling is just copying keys from map to reduce, it has nothing to do with key generation. It is the first phase of a Reducer, with the other two being sorting and then reducing.

Combining is like executing a reducer locally, for the output of each mapper. It basically acts like a reducer (it also extends the Reducer class), which means that, like a reducer, it groups the local values that the mapper has emitted for the same key.

Partitioning is, indeed, assigning the map output keys to specific reduce tasks, but it is not optional. Overriding the default HashPartitioner with an implementation of your own is optional.

"""
The input and output of the combiner needs to be identical (Text,Double -> Text,Double) and it needs to match up with the output of the Mapper and the input of the Reducer.
"""


#How to include data files in python exe.
https://stackoverflow.com/questions/31836104/pyinstaller-and-onefile-how-to-include-an-image-in-the-exe-file

#How to chain jobs. Mutiple mappers & mutiple reducers
https://coe4bd.github.io/HadoopHowTo/multipleJobsSingle/multipleJobsSingle.html

#Mutiple mappers & a single reducer@@@@
http://dailyhadoopsoup.blogspot.com/2014/01/mutiple-input-files-in-mapreduce-easy.html

#TODO
1. Check the output files. There was an error
4 Write up - scratch 12/5
5 Write up - scratch 12/6
6 Write up - done 12/7

#DONE
2. Parallelize the script. 12/2
3. Implement data cleaner 12/3
1. Make it a binary file. 12/4

#How to make Adoop executable
pyinstaller --onefile Adoop.spec

# List all the modules in Python
